{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Objective</h3>\n",
    "I tried the stratified k fold cross validation last time and used the majority vote of the k model predictions to determine the final predictions and that was a slight improvement over earlier.\n",
    "\n",
    "Next, I want to do a quick grid search to find better parameters for plan old vanilla Support Vector Machine. This darling algorithm of so many people can't be that bad at predicting.\n",
    "\n",
    "In my next attempt, I will do a data deep dive. Idea would be to analyze where predictions are going wrong and also to think about what might make better features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Training_data = pd.read_json(\"../input/whatscooking/train.json\")\n",
    "Training_data['str_ingredients'] = Training_data.ingredients.apply(lambda x: ','.join(y for y in x))\n",
    "#describe_dataset(Training_data, \"Training\");\n",
    "Testing_data = pd.read_json(\"../input/whatscooking/test.json\")\n",
    "Testing_data['str_ingredients'] = Testing_data.ingredients.apply(lambda x: ','.join(y for y in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "grouped_ingredients = itertools.groupby(sorted(list(itertools.chain.from_iterable(Training_data.ingredients))))\n",
    "ingredient_counts = {key:len(list(group)) for key, group in grouped_ingredients}\n",
    "global_pantry = pd.DataFrame.from_dict(ingredient_counts, orient='index')\n",
    "global_pantry.columns = ['num_recipes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, vocabulary=global_pantry.index.values)\n",
    "X_Train = vectorizer.fit_transform(Training_data.str_ingredients)\n",
    "y_Train = Training_data.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itemgetter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3a863bdaa783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhyperparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kernel'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gamma'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_Train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtop_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_validation_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'itemgetter' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "model = SVC()\n",
    "hyperparams = {'C': scipy.stats.expon(scale=10), 'kernel': ['rbf', 'linear'], 'gamma': scipy.stats.expon(scale=0.1)}\n",
    "search = RandomizedSearchCV(model, param_distributions=hyperparams, n_iter=10).fit(X_Train, y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "top_score = sorted(search.grid_scores_, key=itemgetter(1), reverse=True)[0]\n",
    "params, perform = top_score.parameters, top_score.mean_validation_score\n",
    "model = SVC(C=params['C'], gamma=params['gamma'], kernel=params['kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 19.379428286962913, 'gamma': 0.29126260414074895, 'kernel': 'rbf'},\n",
       " 0.75848544275154628)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params, perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classifiers: 10, Accuracy: 0.767814018758, Train time: 116.82714932, Test time: 15.6199150085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "\n",
    "Y_Train = Training_data.cuisine\n",
    "stratifiedKFolds = StratifiedKFold(Y_Train, n_folds=10)\n",
    "\n",
    "name = \"SVC_rbf\"\n",
    "classifier_generator = lambda : SVC(C = 19.38, gamma = 0.29, kernel='rbf')\n",
    "\n",
    "classifiers_used = []\n",
    "scores = []\n",
    "train_times = []\n",
    "test_times = []\n",
    "X_Tests = []\n",
    "\n",
    "for train, test in stratifiedKFolds:\n",
    "    \n",
    "    train = Training_data.iloc[train]\n",
    "    test = Training_data.iloc[test]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, vocabulary=global_pantry.index.values)\n",
    "    X_train = vectorizer.fit_transform(train.str_ingredients)\n",
    "    y_train = train.cuisine\n",
    "    X_test = vectorizer.transform(test.str_ingredients)\n",
    "    y_test = test.cuisine\n",
    "    X_Tests.append(vectorizer.transform(Testing_data.str_ingredients))\n",
    "\n",
    "    classifier = classifier_generator()\n",
    "    \n",
    "    t0 = time()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "\n",
    "    t0 = time()\n",
    "    predictions = classifier.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, predictions)\n",
    "\n",
    "    classifiers_used.append(classifier)\n",
    "    scores.append(score)\n",
    "    train_times.append(train_time)\n",
    "    test_times.append(test_time)\n",
    "\n",
    "mean_score = np.mean(scores)\n",
    "mean_train_time = np.mean(train_times)\n",
    "mean_test_time = np.mean(test_time)\n",
    "\n",
    "print \"Number of classifiers: {}, Accuracy: {}, Train time: {}, Test time: {}\".format(\n",
    "    len(classifiers_used), mean_score, mean_train_time, mean_test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 SVC(C=19.38, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.29, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "1 SVC(C=19.38, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.29, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "2 SVC(C=19.38, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.29, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "3 SVC(C=19.38, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.29, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "4 SVC(C=19.38, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.29, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "5 SVC(C=19.38, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.29, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "6 SVC(C=19.38, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.29, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "7 SVC(C=19.38, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.29, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "8 SVC(C=19.38, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.29, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "9 SVC(C=19.38, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.29, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "for i, classifier in enumerate(classifiers_used):\n",
    "    print i, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>str_ingredients</th>\n",
       "      <th>fold0_pred</th>\n",
       "      <th>fold1_pred</th>\n",
       "      <th>fold2_pred</th>\n",
       "      <th>fold3_pred</th>\n",
       "      <th>fold4_pred</th>\n",
       "      <th>fold5_pred</th>\n",
       "      <th>fold6_pred</th>\n",
       "      <th>fold7_pred</th>\n",
       "      <th>fold8_pred</th>\n",
       "      <th>fold9_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 18009</td>\n",
       "      <td> [baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td> baking powder,eggs,all-purpose flour,raisins,m...</td>\n",
       "      <td>        irish</td>\n",
       "      <td>        irish</td>\n",
       "      <td>        irish</td>\n",
       "      <td>      russian</td>\n",
       "      <td>      russian</td>\n",
       "      <td>        irish</td>\n",
       "      <td>        irish</td>\n",
       "      <td>        irish</td>\n",
       "      <td>        irish</td>\n",
       "      <td>        irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 28583</td>\n",
       "      <td> [sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td> sugar,egg yolks,corn starch,cream of tartar,ba...</td>\n",
       "      <td>  southern_us</td>\n",
       "      <td>  southern_us</td>\n",
       "      <td>  southern_us</td>\n",
       "      <td>  southern_us</td>\n",
       "      <td>  southern_us</td>\n",
       "      <td>  southern_us</td>\n",
       "      <td>  southern_us</td>\n",
       "      <td>  southern_us</td>\n",
       "      <td>  southern_us</td>\n",
       "      <td>  southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 41580</td>\n",
       "      <td> [sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td> sausage links,fennel bulb,fronds,olive oil,cub...</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 29752</td>\n",
       "      <td> [meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td> meat cuts,file powder,smoked sausage,okra,shri...</td>\n",
       "      <td> cajun_creole</td>\n",
       "      <td> cajun_creole</td>\n",
       "      <td> cajun_creole</td>\n",
       "      <td> cajun_creole</td>\n",
       "      <td> cajun_creole</td>\n",
       "      <td> cajun_creole</td>\n",
       "      <td> cajun_creole</td>\n",
       "      <td> cajun_creole</td>\n",
       "      <td> cajun_creole</td>\n",
       "      <td> cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 35687</td>\n",
       "      <td> [ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td> ground black pepper,salt,sausage casings,leeks...</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "      <td>      italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...   \n",
       "\n",
       "                                     str_ingredients    fold0_pred  \\\n",
       "0  baking powder,eggs,all-purpose flour,raisins,m...         irish   \n",
       "1  sugar,egg yolks,corn starch,cream of tartar,ba...   southern_us   \n",
       "2  sausage links,fennel bulb,fronds,olive oil,cub...       italian   \n",
       "3  meat cuts,file powder,smoked sausage,okra,shri...  cajun_creole   \n",
       "4  ground black pepper,salt,sausage casings,leeks...       italian   \n",
       "\n",
       "     fold1_pred    fold2_pred    fold3_pred    fold4_pred    fold5_pred  \\\n",
       "0         irish         irish       russian       russian         irish   \n",
       "1   southern_us   southern_us   southern_us   southern_us   southern_us   \n",
       "2       italian       italian       italian       italian       italian   \n",
       "3  cajun_creole  cajun_creole  cajun_creole  cajun_creole  cajun_creole   \n",
       "4       italian       italian       italian       italian       italian   \n",
       "\n",
       "     fold6_pred    fold7_pred    fold8_pred    fold9_pred  \n",
       "0         irish         irish         irish         irish  \n",
       "1   southern_us   southern_us   southern_us   southern_us  \n",
       "2       italian       italian       italian       italian  \n",
       "3  cajun_creole  cajun_creole  cajun_creole  cajun_creole  \n",
       "4       italian       italian       italian       italian  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>cuisine_2</th>\n",
       "      <th>cuisine_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>    9944</td>\n",
       "      <td>     119</td>\n",
       "      <td>          1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>      20</td>\n",
       "      <td>      17</td>\n",
       "      <td>          1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td> italian</td>\n",
       "      <td> italian</td>\n",
       "      <td> vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>    1988</td>\n",
       "      <td>      30</td>\n",
       "      <td>          1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cuisine cuisine_2   cuisine_3\n",
       "count      9944       119           1\n",
       "unique       20        17           1\n",
       "top     italian   italian  vietnamese\n",
       "freq       1988        30           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9944, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>cuisine_2</th>\n",
       "      <th>cuisine_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>        irish</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>  southern_us</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>      italian</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> cajun_creole</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>      italian</td>\n",
       "      <td> NaN</td>\n",
       "      <td> NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cuisine cuisine_2 cuisine_3\n",
       "0         irish       NaN       NaN\n",
       "1   southern_us       NaN       NaN\n",
       "2       italian       NaN       NaN\n",
       "3  cajun_creole       NaN       NaN\n",
       "4       italian       NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 18009</td>\n",
       "      <td>        irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 28583</td>\n",
       "      <td>  southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 41580</td>\n",
       "      <td>      italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 29752</td>\n",
       "      <td> cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 35687</td>\n",
       "      <td>      italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       cuisine\n",
       "0  18009         irish\n",
       "1  28583   southern_us\n",
       "2  41580       italian\n",
       "3  29752  cajun_creole\n",
       "4  35687       italian"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predicted_data = Testing_data.copy()\n",
    "for i, classifier in enumerate(classifiers_used): \n",
    "    Predicted_data['fold{}_pred'.format(i)] = classifier.predict(X_Tests[i])\n",
    "display(Predicted_data.head())\n",
    "\n",
    "majority_vote = Predicted_data[['fold0_pred', \n",
    "                'fold1_pred', \n",
    "                'fold2_pred', \n",
    "                'fold3_pred', \n",
    "                'fold4_pred', \n",
    "                'fold5_pred', \n",
    "                'fold6_pred', \n",
    "                'fold7_pred', \n",
    "                'fold8_pred', \n",
    "                'fold9_pred']].mode(axis=1, numeric_only=False)\n",
    "\n",
    "column_names = ['cuisine']\n",
    "for i in range(2, majority_vote.shape[1]+1):\n",
    "    column_names.append('cuisine_{}'.format(i))\n",
    "majority_vote.columns = column_names\n",
    "display(majority_vote.describe())\n",
    "print majority_vote.shape\n",
    "display(majority_vote.head())\n",
    "\n",
    "#display(majority_vote[majority_vote.cuisine_2.notnull()].head())\n",
    "#display(majority_vote[majority_vote.cuisine.notnull()].head())\n",
    "\n",
    "merged_data = pd.concat([Predicted_data, majority_vote], axis=1)\n",
    "merged_data[['id', 'cuisine']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = merged_data[['id', 'cuisine']]\n",
    "import time\n",
    "submission.to_csv('../output/whatscooking/whatscooking-{}.csv'.format(time.strftime(\"%Y%m%d--%H%M%S\")), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>And this, the seventh submission, is actually the best submission so far, which is heartening.</h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
